# English-to-French-transformer
This is my first attempt at creating a transformer according to the "Attention is All you need" paper (https://arxiv.org/abs/1706.03762) for a translation task the model is acclaimed to give good results for.  I also tried experimenting with different hyperparameters as well as regularization techniques to improve the model's overfitting problem. 

The model, as per the training and architecture that was used in the paper I referenced, didn't achieve the greatest results, however I would like to try different training methods in the future with other transformer-based models I build, particularly trying to find ways to simplify the task the model has to perform, like predicting the next word instead of a sequence of them like the paper shows. I'd also like to see methods to scale this model in possible, and seeing if a larger one would be fit to make the model improve on this task. 

Link to the dataset I used: https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset

